{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "# Add the directory containing MedViT.py and utils.py to the Python path\n",
    "sys.path.append('/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo')\n",
    "\n",
    "# Manually add the MedViT module to sys.modules\n",
    "medvit_module_name = \"MedViT\"\n",
    "medvit_file_path = \"/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo/modules/MedViT.py\"\n",
    "utils_file_path = \"/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo/modules/utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(medvit_module_name, medvit_file_path)\n",
    "medvit_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[medvit_module_name] = medvit_module\n",
    "spec.loader.exec_module(medvit_module)\n",
    "\n",
    "# Load the utils module\n",
    "utils_spec = importlib.util.spec_from_file_location(\"utils\", utils_file_path)\n",
    "utils_module = importlib.util.module_from_spec(utils_spec)\n",
    "utils_spec.loader.exec_module(utils_module)\n",
    "\n",
    "# Import any other necessary modules or components from MedViT and utils\n",
    "from MedViT import MedViT_small\n",
    "\n",
    "# Instantiate the model\n",
    "model = MedViT_small(pretrained=True)\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "num_classes = 5\n",
    "model.proj_head = nn.Sequential(\n",
    "    nn.Linear(model.proj_head[0].in_features, num_classes)\n",
    ")\n",
    "\n",
    "# Send the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the utils module\n",
    "utils_file_path = \"/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo/modules/utils.py\"\n",
    "utils_spec = importlib.util.spec_from_file_location(\"utils\", utils_file_path)\n",
    "utils_module = importlib.util.module_from_spec(utils_spec)\n",
    "utils_spec.loader.exec_module(utils_module)\n",
    "\n",
    "# Pass the merge_pre_bn function to MedViT.py\n",
    "medvit_file_path = \"/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo/modules/MedViT.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"MedViT\", medvit_file_path)\n",
    "medvit_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(medvit_module)\n",
    "\n",
    "# Assuming the model class is named MedViT in the module\n",
    "#model = medvit_module.MedViT(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data Preparation\n",
    "class KneeDataset(Dataset):\n",
    "    def __init__(self, data_path, categories, img_size=224):\n",
    "        self.data_path = data_path\n",
    "        self.categories = categories\n",
    "        self.img_size = img_size\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_dict = {category: i for i, category in enumerate(categories)}\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        for category in self.categories:\n",
    "            folder_path = os.path.join(self.data_path, category)\n",
    "            img_names = os.listdir(folder_path)\n",
    "            for img_name in img_names:\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "                    img = (img - 128) / 128 * 1024  # Normalize to [-1024, 1024]\n",
    "                    self.data.append(img)\n",
    "                    self.labels.append(self.label_dict[category])\n",
    "\n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        img = np.transpose(img, (2, 0, 1))  # Convert to CxHxW\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "data_path = '/Users/apple/Desktop/PG/Summer-24/image-DL/knee-arthritis-detection-algo/Training'\n",
    "categories = ['1Doubtful', '4Severe', '2Mild', '0Normal', '3Moderate']\n",
    "img_size = 224\n",
    "\n",
    "dataset = KneeDataset(data_path, categories, img_size)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}, Best Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    scheduler.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
